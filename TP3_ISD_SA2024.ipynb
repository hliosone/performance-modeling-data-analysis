{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b123e229",
   "metadata": {},
   "source": [
    "# Introduction à la Science des données\n",
    "\n",
    "\n",
    "## Travail pratique 03 - Modélisation et analyse de performances\n",
    "\n",
    "[Table des matières](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b5805e",
   "metadata": {},
   "source": [
    "**Informations de groupe - Prénoms et noms complets:**\n",
    "\n",
    "- Fehlmann Dylan\n",
    "- Stelcher Stan\n",
    "- ...\n",
    "\n",
    "**Professeurs**: Carlos Peña et Stephan Robert\n",
    "\n",
    "**Assistant(s)**: Thibault Schowing, Arthur Babey, Cédric Campos Carvalho\n",
    "\n",
    "**Contact**: prenom.nom@heig-vd.ch ou de préférence via Teams \n",
    "\n",
    "### Modalités de rendu :\n",
    "\n",
    "- **Date**: <span style=\"background-color:#eebbdd\">01.12.2024, 23h55</span>\n",
    "\n",
    "\n",
    "- **Travail par groupe** de 2 ou 3. \n",
    "\n",
    "\n",
    "- Une fois complété, rendez directement le notebook (fichier avec l'extension _.ipynb_) nommé correctement comme suit <span style=\"background-color:#eebbdd\">\"**TP3_ISD_SA2024_Nom1_Nom2(_Nom3).ipynb**\"</span> en mettant les noms de famille de chaque membres du groupe (pour ceux avec plusieurs noms de famille, vous pouvez mettre juste le premier comme dans l'adresse email). Les TPs rendu avec un fichier mal nommé seront pénalisé !\n",
    "\n",
    "\n",
    "- Mettez vos Prénoms et noms en entier ci-dessus. \n",
    "\n",
    "\n",
    "- Uploadez le fichier complété avant le délais sur Cyberlearn ou Teams selon les consignes données. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850ad687",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Déroulement et notation\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Les questions</b> sont généralement indiquées en <b>gras</b>, en <span style=\"background-color:#AFEEEE\">bleu</span> ou par une liste d'instructrions et les endroits où répondre sont indiqués par un \"<i>Réponse:</i>\" pour les réponses textuelles. Pour les réponses nécessitant d'écrire du code, les cellules ont déjà été crées et un commentaire indique où/quoi répondre. \n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b>Notation: </b> Ce TP est noté sur 6 avec un total de  <span style=\"background-color:#eebbdd\"><b>80</b></span> points. Les points sont indiqués pour chaques parties du travail pour un total de <span style=\"background-color:#eebbdd\"><b>76</b></span> points  et <span style=\"background-color:#eebbdd\"><b>4</b></span> points supplémentaires sont attribués au rendu du travail (format et nommage selon les consignes) et à la propreté (lisibilité et mise en page, tournure de phrase des réponses). \n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Corrections: </b> Ce notebook vous sera renvoyé via Cyberlearn/Teams ou un autre canal. Les informations principales concernant les corrections seront indiquées après chaque section (banière bleue) avec le nombre de points obtenus. Il est possible que des remarques concernant le code soient directement ajoutées dans celui-ci.\n",
    "</div>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3062f97e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Objectifs </b>\n",
    "</div>\n",
    "\n",
    "- Comprendre la modélisation avec un modèle simple: le modèle à base de règles\n",
    "- Analyse des résultats avec la matrice de confusion\n",
    "- Algorithme kNN\n",
    "- Évaluation des performances avec Validation hold-out et N-Fold Crossvalidation. \n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Aide </b>\n",
    "</div>\n",
    "\n",
    "N'oubliez pas que vous pouvez retourner vers les TPs précédents si vous avez des questions sur Python, Numpy, Pandas ou Matplotlib. Gardez vos cheatsheets à proximité !\n",
    "\n",
    "- [Data wrangling with Pandas](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)\n",
    "- [Matplotlib cheatscheets](https://matplotlib.org/cheatsheets/)\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>N'hésitez pas à écrire à vos assistants directement sur Teams en cas de question.  </b>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617af72d",
   "metadata": {},
   "source": [
    "\n",
    "<!-- @import \"[TOC]\" {cmd=\"toc\" depthFrom=1 depthTo=6 orderedList=false} -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010106eb",
   "metadata": {},
   "source": [
    "### Table des matières<a class=\"anchor\"  id=\"toc\"></a>\n",
    "\n",
    "\n",
    "[Partie 1: Modèle à base de règles](#Part1)\n",
    "\n",
    "[- 1.1 Analyse exploratoire](#Part11)\n",
    "\n",
    "[- 1.2 Boxplots, pairplot et choix des variables](#Part12)     ---    [20 points](#Part112pts)\n",
    "\n",
    "[- 1.3 Création du modèle à base de règles](#Part13)\n",
    "\n",
    "[- 1.4 Matrice de confusion](#Part14)     ---    [16 points](#Part134pts)\n",
    "\n",
    "---\n",
    "\n",
    "[Partie 2: L'algorithme des k plus proches voisins (k-NN) ](#Part2)  \n",
    "\n",
    "[- 2.1 Implémentation](#Part21)    ----    [12 points](#Part21pts)\n",
    "\n",
    "[- 2.2 Validation hold-out](#Part22)    ----    [10 points](#Part22pts)\n",
    "\n",
    "[- 2.3 N-Folds Cross Validation](#Part23)    ----    [10 points](#Part23pts)\n",
    "\n",
    "[- 2.4 Conclusion](#Part24)    ----    [8 points](#Part24pts)\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<p style=\"background-color:#7ba3e3;padding:10px\"><font size=\"6\"><b></b></font></p>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bc4c64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from math import sqrt\n",
    "import itertools\n",
    "\n",
    "# Package scikit-learn\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "# Pour k-NN\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Pour validation hold-out\n",
    "\n",
    "import random\n",
    "from random import randrange\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e39d17",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7569cb7e",
   "metadata": {},
   "source": [
    "\n",
    "## Partie 1 - Modèle à base de règles<a class=\"anchor\"  id=\"Part1\"></a>\n",
    "\n",
    "[Table des matières](#toc)\n",
    "\n",
    "[- 1.1 Analyse exploratoire](#Part11)\n",
    "\n",
    "[- 1.2 Boxplots, pairplot et choix des variables](#Part12)     ---    [20 points](#Part112pts)\n",
    "\n",
    "[- 1.3 Création du modèle à base de règles](#Part13)\n",
    "\n",
    "[- 1.4 Matrice de confusion](#Part14)     ---    [16 points](#Part134pts)\n",
    "\n",
    "Dans cette partie, nous allons créer un modèle de classification simple. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4320b2",
   "metadata": {},
   "source": [
    "---\n",
    "<a class=\"anchor\"  id=\"Part11\"></a>\n",
    "### 1.1 Analyse exploratoire\n",
    "\n",
    "[Début partie 1](#Part1) --- [Table des matières](#toc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15361308",
   "metadata": {},
   "source": [
    "Nous allons utiliser la base de données «Wine Data Set » disponible sur le dépôt de bases de données maintenu par l’Université de Californie à Irvine (UCI). Le lien est celui-ci : [http://archive.ics.uci.edu/ml/datasets/Wine?Quality].\n",
    "\n",
    "Créez un DataFrame à partir du fichier **wine.data** et des noms de colonnes fournis, puis explorez rapidement les données. Ouvrez rapidement le fichier et observez les données pour voir leur structure et mieux comprendre la suite et posez-vous ces questions (pas besoin de noter une réponse): \n",
    "\n",
    "- *De quel manière sont stockées les données ?* \n",
    "- *Pourquoi on nous donne une liste de noms de colonne ?*\n",
    "\n",
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Exercice </b></font> Chargez les données comme indiqué ci-dessous. Si vous le voulez vous pouvez directement charger ces données depuis Scikit-learn, à vous de trouver comment faire.</p>\n",
    "(2 points)\n",
    "\n",
    "\n",
    "\n",
    "Notes:\n",
    "\n",
    "- Utilisez la fonction read_csv() pour lire le fichier **wine.data** et spécifiez le paramètre *names* en lui passant la liste donnée ci-dessous.\n",
    "- La fonction [_unique()_](https://pandas.pydata.org/docs/reference/api/pandas.unique.html) peut vous être utile !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6510820d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Class      Alcool  Malic acid         Ash  Alcalinity of ash  \\\n",
      "count  178.000000  178.000000  178.000000  178.000000         178.000000   \n",
      "mean     1.938202   13.000618    2.336348    2.366517          19.494944   \n",
      "std      0.775035    0.811827    1.117146    0.274344           3.339564   \n",
      "min      1.000000   11.030000    0.740000    1.360000          10.600000   \n",
      "25%      1.000000   12.362500    1.602500    2.210000          17.200000   \n",
      "50%      2.000000   13.050000    1.865000    2.360000          19.500000   \n",
      "75%      3.000000   13.677500    3.082500    2.557500          21.500000   \n",
      "max      3.000000   14.830000    5.800000    3.230000          30.000000   \n",
      "\n",
      "        Magnesium  Total phenols  Flavanoids  Nonflavanoid phenols  \\\n",
      "count  178.000000     178.000000  178.000000            178.000000   \n",
      "mean    99.741573       2.295112    2.029270              0.361854   \n",
      "std     14.282484       0.625851    0.998859              0.124453   \n",
      "min     70.000000       0.980000    0.340000              0.130000   \n",
      "25%     88.000000       1.742500    1.205000              0.270000   \n",
      "50%     98.000000       2.355000    2.135000              0.340000   \n",
      "75%    107.000000       2.800000    2.875000              0.437500   \n",
      "max    162.000000       3.880000    5.080000              0.660000   \n",
      "\n",
      "       Proanthocyanins  Color intensity         Hue  \\\n",
      "count       178.000000       178.000000  178.000000   \n",
      "mean          1.590899         5.058090    0.957449   \n",
      "std           0.572359         2.318286    0.228572   \n",
      "min           0.410000         1.280000    0.480000   \n",
      "25%           1.250000         3.220000    0.782500   \n",
      "50%           1.555000         4.690000    0.965000   \n",
      "75%           1.950000         6.200000    1.120000   \n",
      "max           3.580000        13.000000    1.710000   \n",
      "\n",
      "       OD280/OD315 of diluted wines      Proline  \n",
      "count                    178.000000   178.000000  \n",
      "mean                       2.611685   746.893258  \n",
      "std                        0.709990   314.907474  \n",
      "min                        1.270000   278.000000  \n",
      "25%                        1.937500   500.500000  \n",
      "50%                        2.780000   673.500000  \n",
      "75%                        3.170000   985.000000  \n",
      "max                        4.000000  1680.000000  \n",
      "\n",
      "Classes uniques :\n",
      "[1 2 3]\n",
      "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
      "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
      "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
      "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
      "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
      "\n",
      "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
      "0        3.06                  0.28             2.29             5.64  1.04   \n",
      "1        2.76                  0.26             1.28             4.38  1.05   \n",
      "2        3.24                  0.30             2.81             5.68  1.03   \n",
      "3        3.49                  0.24             2.18             7.80  0.86   \n",
      "4        2.69                  0.39             1.82             4.32  1.04   \n",
      "\n",
      "   od280/od315_of_diluted_wines  proline  Class  \n",
      "0                          3.92   1065.0      0  \n",
      "1                          3.40   1050.0      0  \n",
      "2                          3.17   1185.0      0  \n",
      "3                          3.45   1480.0      0  \n",
      "4                          2.93    735.0      0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# Noms de colonnes \n",
    "\n",
    "headers = ['Class', 'Alcool', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium', \n",
    "           'Total phenols', 'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', \n",
    "           'Hue', 'OD280/OD315 of diluted wines', 'Proline']\n",
    "\n",
    "# Créez le dataset et nommez le \"wines\"\n",
    "# Ajoutez votre code ici.\n",
    "\n",
    "wines = pd.read_csv('wine.data', header=None, names=headers)\n",
    "print(wines.describe())\n",
    "print(\"\\nClasses uniques :\")\n",
    "print(wines[\"Class\"].unique())\n",
    "\n",
    "sklearn_wine_data = load_wine()\n",
    "df_sklearn = pd.DataFrame(data=sklearn_wine_data.data, columns=sklearn_wine_data.feature_names)\n",
    "df_sklearn[\"Class\"] = sklearn_wine_data.target\n",
    "print(df_sklearn.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c55d92",
   "metadata": {},
   "source": [
    "Explorez rapidement les données avec les fonctions habituelles pour récolter des informations (p.ex., nombre d’observations, de classes, d’attributs, statistiques des attributs, données manquantes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "174a9f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Class      Alcool  Malic acid         Ash  Alcalinity of ash  \\\n",
      "count  178.000000  178.000000  178.000000  178.000000         178.000000   \n",
      "mean     1.938202   13.000618    2.336348    2.366517          19.494944   \n",
      "std      0.775035    0.811827    1.117146    0.274344           3.339564   \n",
      "min      1.000000   11.030000    0.740000    1.360000          10.600000   \n",
      "25%      1.000000   12.362500    1.602500    2.210000          17.200000   \n",
      "50%      2.000000   13.050000    1.865000    2.360000          19.500000   \n",
      "75%      3.000000   13.677500    3.082500    2.557500          21.500000   \n",
      "max      3.000000   14.830000    5.800000    3.230000          30.000000   \n",
      "\n",
      "        Magnesium  Total phenols  Flavanoids  Nonflavanoid phenols  \\\n",
      "count  178.000000     178.000000  178.000000            178.000000   \n",
      "mean    99.741573       2.295112    2.029270              0.361854   \n",
      "std     14.282484       0.625851    0.998859              0.124453   \n",
      "min     70.000000       0.980000    0.340000              0.130000   \n",
      "25%     88.000000       1.742500    1.205000              0.270000   \n",
      "50%     98.000000       2.355000    2.135000              0.340000   \n",
      "75%    107.000000       2.800000    2.875000              0.437500   \n",
      "max    162.000000       3.880000    5.080000              0.660000   \n",
      "\n",
      "       Proanthocyanins  Color intensity         Hue  \\\n",
      "count       178.000000       178.000000  178.000000   \n",
      "mean          1.590899         5.058090    0.957449   \n",
      "std           0.572359         2.318286    0.228572   \n",
      "min           0.410000         1.280000    0.480000   \n",
      "25%           1.250000         3.220000    0.782500   \n",
      "50%           1.555000         4.690000    0.965000   \n",
      "75%           1.950000         6.200000    1.120000   \n",
      "max           3.580000        13.000000    1.710000   \n",
      "\n",
      "       OD280/OD315 of diluted wines      Proline  \n",
      "count                    178.000000   178.000000  \n",
      "mean                       2.611685   746.893258  \n",
      "std                        0.709990   314.907474  \n",
      "min                        1.270000   278.000000  \n",
      "25%                        1.937500   500.500000  \n",
      "50%                        2.780000   673.500000  \n",
      "75%                        3.170000   985.000000  \n",
      "max                        4.000000  1680.000000  \n",
      "\n",
      "Classes uniques :\n",
      "[1 2 3]\n",
      "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
      "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
      "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
      "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
      "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
      "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
      "\n",
      "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
      "0        3.06                  0.28             2.29             5.64  1.04   \n",
      "1        2.76                  0.26             1.28             4.38  1.05   \n",
      "2        3.24                  0.30             2.81             5.68  1.03   \n",
      "3        3.49                  0.24             2.18             7.80  0.86   \n",
      "4        2.69                  0.39             1.82             4.32  1.04   \n",
      "\n",
      "   od280/od315_of_diluted_wines  proline  Class  \n",
      "0                          3.92   1065.0      0  \n",
      "1                          3.40   1050.0      0  \n",
      "2                          3.17   1185.0      0  \n",
      "3                          3.45   1480.0      0  \n",
      "4                          2.93    735.0      0  \n"
     ]
    }
   ],
   "source": [
    "# Ajoutez votre code ici. Ajoutez des cellules si nécessaire. \n",
    "\n",
    "wines = pd.read_csv('wine.data', header=None, names=headers)\n",
    "print(wines.describe())\n",
    "print(\"\\nClasses uniques :\")\n",
    "print(wines[\"Class\"].unique())\n",
    "\n",
    "sklearn_wine_data = load_wine()\n",
    "df_sklearn = pd.DataFrame(data=sklearn_wine_data.data, columns=sklearn_wine_data.feature_names)\n",
    "df_sklearn[\"Class\"] = sklearn_wine_data.target\n",
    "print(df_sklearn.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaa78cf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font> La colonne \"Class\" contient notre variable dépendante (variable de sortie / output). Combien de classes différentes y a-t-il et à quoi correspondent-elles ? A quelle position se trouve cette colonne dans le DataFrame ?  </p> (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926f993d",
   "metadata": {},
   "source": [
    "*Réponses:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcdabbe",
   "metadata": {},
   "source": [
    "---\n",
    "<a name=\"Part12\"></a>\n",
    "### 1.2 Boxplots, pairplot et choix des variables\n",
    "\n",
    "[Début partie 1](#Part1) --- [Table des matières](#toc)\n",
    "\n",
    "\n",
    "Maintenant que nous connaissons mieux les données, nous pouvons visualiser les différences entre classes afin de pouvoir créer des règles de classification. Le but, est de trouver des valeurs de variables permettant de séparer les différentes classes du mieux possible afin de pouvoir classifier de nouveaux vins. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11439656",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Exercice </b></font> Créez un boxplot pour chaque variables, groupées par Class.</p>\n",
    "(4 points)\n",
    "\n",
    "Pour faire ceci, complétez le code ci-dessous en vous basant sur le pseudo code donné en commentaire entre les \"------\". N'utilisez que 2 lignes: une pour la boucle et une pour le graphique.\n",
    "\n",
    "- Aide: Pour obtenir les noms de colonnes utilisez *wines.columns*. Pour obtenir i dans la boucle, en plus des noms de colonne, utilisez la fonction *enumerate*.\n",
    "- Aide: Utilisez le [slicing](https://stackoverflow.com/questions/509211/understanding-slicing) pour obtenir tous les noms de colonne sauf Class (qui se trouve à une extrémité de la liste). \n",
    "- Aide: Utilisez la fonction [sns.boxplot de Seaborn](https://seaborn.pydata.org/generated/seaborn.boxplot.html) pour un résultat élégant très coloré, ou la fonction [pandas.DataFrame.boxplot](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.boxplot.html) pour un résultat épuré en toute simplicité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615ca6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 7, figsize=(20, 10)) # On spécifie le nombre de lignes et de colonnes de notre figure \n",
    "axs = axs.flatten() # -> 1D\n",
    "\n",
    "#----------\n",
    "# Pour i et chaque nom de colonne sauf class\n",
    "    # Boxplot avec pour x la Class, et pour y la variable. Utilisez ax=axs[i] pour insérer le plot dans la figure. !\n",
    "#----------  \n",
    "\n",
    "for i, col in enumerate(wines.columns[1:]):\n",
    "    sns.boxplot(x=\"Class\", y=col, data=wines, ax=axs[i]) \n",
    "\n",
    "\n",
    "fig.suptitle('Boxplot of the features by label', fontsize=14)    \n",
    "fig.tight_layout(rect=[0, 0.03, 1, 0.98])\n",
    "fig.delaxes(axs[13])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dd23ad",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Exercice </b></font> Créez un Pairplot à l'aide de la librairie Seaborn</p>\n",
    "(4 points)\n",
    "\n",
    "****\n",
    "\n",
    "Pour les données avec \"peu\" de variables, comme dans notre cas, un pairplot peut permettre d'obtenir une excellente vue d'ensemble. Cependant, la génération du pairplot peut prendre un certain temps. Pour éviter de prendre du temps à générer et re-générer le pairplot, vous pouvez commenter votre code une fois que vous avez analysé le graphique.\n",
    "\n",
    "Note: Vous pouvez désactiver les Warnings s'il y en a. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9498ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot avec Seaborn - Votre code\n",
    "\n",
    "# Désactiver les warnings s'il y en a\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.pairplot(wines, hue=\"Class\", diag_kind=\"kde\", palette=\"tab10\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1cd20e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3de225",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font>Quels éléments du pairplot permettent de rapidement distinguer les différences entre les 3 classes ? </p> (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cab398",
   "metadata": {},
   "source": [
    "*Réponse:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a34e49a",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font> D'après les boxplots, quelles variables permettraient le mieux de distinguer/séparer les trois classes ? Et de distinguer une classe des deux autres ? Donnez 5 variables (en tout) soit pour séparer les 3 classes soit une des deux autres, ainsi que les valeurs approximatives de séparration. Justifiez et discutez votre choix. </p> (6 points)\n",
    "\n",
    "<p></p>\n",
    "<div style=\"background-color:#EEEEEE;padding:3px\">Note: un modèle avec des règles simples peut permettre, par exemple, de distinguer deux classes l'une de l'autre. Par exemple pour distinguer un chat d'un chien sur des valeurs numérique on pourrait avoir les règles suivantes: \n",
    "\n",
    "- Si $souplesse < 2$ et $poids > 10$ -> c'est un chien\n",
    "- Sinon -> c'est un chat. \n",
    "\n",
    "Pour pouvoir établir ces règles, il faut donc avoir une vue sur les différentes variables. Ce n'est pas parfait mais le modèle reste simple. Il fonctionnera dans une bonne partie des cas mais on peut toujours tomber sur un Chihuahua souple de moins de 5 kilos par exemple. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2588abca",
   "metadata": {},
   "source": [
    "*Réponse:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c45a115",
   "metadata": {},
   "source": [
    "<a name=\"Part112pts\"></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Corrections Partie 1.1 - 1.2: </b> Points obtenus: /20\n",
    "</div>\n",
    "\n",
    "Remarques de l'assistant: \n",
    "- Load data /2\n",
    "- Q /2\n",
    "- Plots /8\n",
    "- Q /2\n",
    "- Q /6\n",
    "\n",
    "\n",
    "[Début partie 1](#Part1) --- [Table des matières](#toc)\n",
    "\n",
    "<p style=\"background-color:#003c9c;padding:3px\"><font size=\"4\"><b></b></font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a720b4b",
   "metadata": {},
   "source": [
    "<a name=\"Part13\"></a>\n",
    "### 1.3 Création du modèle à base de règles\n",
    "\n",
    "[Début partie 1](#Part1) --- [Table des matières](#toc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e01691",
   "metadata": {},
   "source": [
    "Suivez la structure du code ci-après pour implémenter un modèle à base de règles. Complétez les parties manquantes et écrivez les fonctions demandées. **Lisez bien les commentaires afin de bien comprendre la logique implémentée**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eb5929",
   "metadata": {},
   "source": [
    "#### 1.3.1 Définition des règles\n",
    "\n",
    "Dans cette partie vous allez écrire les règles permettant de distinguer les trois classes (Note) à l'aide des variables `Alcool`, `Color intensity` et `Flavanoids`. Utilisez pour cela les valeurs que vous avez trouvées au TP3 ou servez vous des graphiques ci-dessus pour les déterminer. \n",
    "\n",
    "Servez-vous de la fonction donnée en exemple pour créer les fonctions suivantes (**respectez les noms !**): \n",
    "\n",
    "- *class_by_alcool()*: utilise la variable Alcool uniquement. \n",
    "- *class_by_flavanoids()*: utilise la variable Flavanoids uniquement.\n",
    "- *class_by_color_intensity()*: utilise la variable Color intensity uniquement\n",
    "- *class_by_flav_alcool()*: utilise les variables Flavanoids et Alcool\n",
    "- *class_by_color_alcool()*: utilise les variables Color intensity et Alcool\n",
    "- *class_by_color_flav()*: utilise les variables Color intensity et Flavanoids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39c376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les fonctions suivantes seront appliquées au DataFrame à l'aide de la fonction apply(). \n",
    "# Le DataFrame sera donc passé en paramètres et les opérations effectuées sur toutes les observations. \n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Définition des règles\n",
    "# ------------------------------------------------------------------\n",
    "'''\n",
    "def class_by_XXXXXX(df): # ou class_by_XXXXXX_YYYYYY(df):\n",
    "    \"\"\"\n",
    "    Retourne la classe (1, 2 ou 3) selon la variable XXXXXX (et YYYYYY -> en ayant accès à tout le dataframe, on peut\n",
    "    aussi tester une seconde variable ou plus).\n",
    "    \"\"\"\n",
    "    if(df[\"XXXXXX\"] > 42 and....):\n",
    "        return 1\n",
    "    elif(df[\"YYYYYY\"] > 42):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "'''\n",
    "\n",
    "# Fonction pour distinguer les classes uniquement avec la variable Alcool\n",
    "def class_by_alcool(df):\n",
    "    if df[\"Alcool\"] > 13.5:\n",
    "        return 1\n",
    "    elif 12.5 < df[\"Alcool\"] <= 13.5:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "# Fonction pour distinguer les classes uniquement avec la variable Flavanoids\n",
    "def class_by_flavanoids(df):\n",
    "    if df[\"Flavanoids\"] > 2.5:\n",
    "        return 1\n",
    "    elif 1.5 < df[\"Flavanoids\"] <= 2.5:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "# Fonction pour distinguer les classes uniquement avec la variable Color intensity\n",
    "def class_by_color_intensity(df):\n",
    "    if df[\"Color intensity\"] > 7:\n",
    "        return 3\n",
    "    elif 5 < df[\"Color intensity\"] <= 7:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Fonction pour distinguer les classes avec les variables Flavanoids et Alcool\n",
    "def class_by_flav_alcool(df):\n",
    "    if df[\"Flavanoids\"] > 2.5 and df[\"Alcool\"] > 13.5:\n",
    "        return 1\n",
    "    elif df[\"Flavanoids\"] <= 2.5 and 12.5 < df[\"Alcool\"] <= 13.5:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "# Fonction pour distinguer les classes avec les variables Color intensity et Alcool\n",
    "def class_by_color_alcool(df):\n",
    "    if df[\"Color intensity\"] > 7 and df[\"Alcool\"] < 12.5:\n",
    "        return 3\n",
    "    elif 5 < df[\"Color intensity\"] <= 7 and 12.5 < df[\"Alcool\"] <= 13.5:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Fonction pour distinguer les classes avec les variables Color intensity et Flavanoids\n",
    "def class_by_color_flav(df):\n",
    "    if df[\"Color intensity\"] > 7 and df[\"Flavanoids\"] <= 1.5:\n",
    "        return 3\n",
    "    elif 5 < df[\"Color intensity\"] <= 7 and 1.5 < df[\"Flavanoids\"] <= 2.5:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dbf54a",
   "metadata": {},
   "source": [
    "#### 1.3.2 Prédictions\n",
    "\n",
    "Pour chacune des règles créées ci-dessus, ajoutez une colonne dans df, une copie du DataFrame wines. Utilisez des noms parlants comme \"pred_alcool\" ou \"pred_alcool_flav\" afin que l'on comprenne bien de quelle prédiction il s'agit. Un exemple de l'utilisation de la fonction apply() est donné en commentaire. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df646498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Creation de la / des colonnes de prédiction \n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# Copie du DataFrame pour ne pas modifier l'original accidentellement. \n",
    "df = wines.copy()\n",
    "\n",
    "\n",
    "# Créez une nouvelle colonne qui contient le résultat de la fonction class_by_YYYYYY\n",
    "# Faites le pour chaque fonction créées ci-dessus. \n",
    "\n",
    "# Ajout des colonnes de prédictions pour chaque règle définie\n",
    "df[\"pred_alcool\"] = df.apply(class_by_alcool, axis=1)\n",
    "df[\"pred_flavanoids\"] = df.apply(class_by_flavanoids, axis=1)\n",
    "df[\"pred_color_intensity\"] = df.apply(class_by_color_intensity, axis=1)\n",
    "df[\"pred_flav_alcool\"] = df.apply(class_by_flav_alcool, axis=1)\n",
    "df[\"pred_color_alcool\"] = df.apply(class_by_color_alcool, axis=1)\n",
    "df[\"pred_color_flav\"] = df.apply(class_by_color_flav, axis=1)\n",
    "print(df.head())\n",
    "\n",
    "# Exemple: df[\"pred_NNN\"] = df.apply(class_by_YYYYYY, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a97f34",
   "metadata": {},
   "source": [
    "<a name=\"Part14\"></a>\n",
    "### 1.4 Matrice de confusion\n",
    "\n",
    "[Début partie 1](#Part1) --- [Table des matières](#toc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0664a2a4",
   "metadata": {},
   "source": [
    "Affichez les scores (Accuracy) et matrices de confusion pour chaque règles. Pour cela, on utilise les fonctions **accuracy_score()**, **confusion_matrix()** et **ConfusionMatrixDisplay()** fournies par ScikitLearn et importée en amont de ce Notebook. \n",
    "\n",
    "Inspirez-vous du code partiellement donné en exemple ci-dessous. Vos résultats doivent cependant être présentés de manière à ce qu'on puisse savoir à quelle règle correspond quelle accuracy /  matrice de confusion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07005cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------\n",
    "# Pour chaque modèle (6x), affichez le score (Accuracy) et la matrice de confusion (code ci-dessous)\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# Vous pouvez écrire une boucle pour afficher le score et la matrice à la suite ou dans des cellules séparées. \n",
    "# Libre à vous de choisir la solution qui vous plait le plus !\n",
    "\n",
    "'''\n",
    "score = accuracy_score(...)\n",
    "print(f\"Accuracy: {score}\")\n",
    "\n",
    "cm = confusion_matrix(...)\n",
    "disp = ConfusionMatrixDisplay(...)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "'''\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Liste des colonnes de prédictions\n",
    "pred_columns = [\n",
    "    \"pred_alcool\", \n",
    "    \"pred_flavanoids\", \n",
    "    \"pred_color_intensity\", \n",
    "    \"pred_flav_alcool\", \n",
    "    \"pred_color_alcool\", \n",
    "    \"pred_color_flav\"\n",
    "]\n",
    "\n",
    "# Boucle pour calculer et afficher accuracy et matrices de confusion\n",
    "for col in pred_columns:\n",
    "    print(f\"### Résultats pour {col} ###\")\n",
    "    \n",
    "    # Calcul de l'accuracy\n",
    "    score = accuracy_score(df[\"Class\"], df[col])\n",
    "    print(f\"Accuracy: {score}\")\n",
    "    \n",
    "    # Calcul de la matrice de confusion\n",
    "    cm = confusion_matrix(df[\"Class\"], df[col])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[1, 2, 3])\n",
    "    \n",
    "    # Affichage de la matrice\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title(f\"Matrice de confusion pour {col}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0118b40d",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font>Laquelle de vos règles donne le meilleur résultat ? Y a-t-il une classe plus difficile à prédir qu'une autre ?</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd7f4b4",
   "metadata": {},
   "source": [
    "*Réponses:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe9c7e9",
   "metadata": {},
   "source": [
    "<a name=\"Part134pts\"></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Corrections Partie 1.3 - 1.4: </b> Points obtenus: /16\n",
    "</div>\n",
    "\n",
    "Remarques de l'assistant: \n",
    "- Règles (6) et prédictions (4 pts): /10\n",
    "- Matrices de confusion: /4\n",
    "- Question: /2\n",
    "\n",
    "\n",
    "[Début partie 1](#Part1) --- [Table des matières](#toc)\n",
    "\n",
    "<p style=\"background-color:#003c9c;padding:3px\"><font size=\"4\"><b></b></font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626b4d61",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<p style=\"background-color:#7ba3e3;padding:10px\"><font size=\"6\"><b></b></font></p>\n",
    "\n",
    "---\n",
    "\n",
    "<a name=\"Part2\"></a>\n",
    "\n",
    "## Partie 2 - L'algorithme des k plus proches voisins (k-NN) \n",
    "\n",
    "[Table des matières](#toc)\n",
    "\n",
    "Dans cet exercice, nous allons utiliser KNN pour traiter le problème de classification des vins.  \n",
    "\n",
    "\n",
    "[- 2.1 Implémentation](#Part21)    ----    [12 points](#Part21pts)\n",
    "\n",
    "[- 2.2 Validation hold-out](#Part22)    ----    [10 points](#Part22pts)\n",
    "\n",
    "[- 2.3 N-Folds Cross Validation](#Part23)    ----    [10 points](#Part23pts)\n",
    "\n",
    "[- 2.4 Conclusion](#Part24)    ----    [8 points](#Part24pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7028eb",
   "metadata": {},
   "source": [
    "<a name=\"Part21\"></a>\n",
    "### 2.1 Implémentation et préparration des données\n",
    "[Table des matières](#toc)\n",
    "\n",
    "Le code suivant est tiré du cours. Complétez les [docstrings](https://www.datacamp.com/tutorial/docstrings-python#multi-line-docstring-multi) de manière à indiquer ce que fait la fonction, quels sont les paramètres ainsi que la valeur de retour. Ajoutez en plus des commentaires sur les parties complexes afin de montrer que vous avez compris l'implémentation de KNN. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779ff8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code du cours - TODO Complétez les docstrings \n",
    "\n",
    "\n",
    "def train_test_split(dataset, split=0.60):\n",
    "    \"\"\"\n",
    "    Divise un dataset en deux sous-ensembles : un ensemble d'entraînement et un ensemble de test.\n",
    "    \n",
    "    Args:\n",
    "        dataset (list): Le dataset initial sous forme de liste.\n",
    "        split (float): Le ratio d'entraînement (par défaut 0.60). \n",
    "                       Par exemple, 0.60 signifie 60% des données seront utilisées pour l'entraînement.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Une paire (train, test), où :\n",
    "               - train (list) est l'ensemble d'entraînement.\n",
    "               - test (list) est l'ensemble de test.\n",
    "    \n",
    "    \"\"\"\n",
    "    train = list()\n",
    "    train_size = split * len(dataset)\n",
    "    test = list(dataset)\n",
    "    while len(train) < train_size:\n",
    "        index = randrange(len(test))\n",
    "        train.append(test.pop(index))\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def euclidean_distance(row1, row2):\n",
    "    \"\"\"\n",
    "    Calcule la distance euclidienne entre deux vecteurs (lignes du dataset).\n",
    "\n",
    "    Args:\n",
    "        row1 (list): La première ligne (vecteur) sous forme de liste.\n",
    "        row2 (list): La deuxième ligne (vecteur) sous forme de liste.\n",
    "\n",
    "    Returns:\n",
    "        float: La distance euclidienne entre les deux vecteurs.\n",
    "    \"\"\"\n",
    "\n",
    "    distance = 0.0\n",
    "    for i in range(1, len(row1)): # All columns except the first one (Note) - Wrong in course's PDF\n",
    "        distance += (row1[i] - row2[i])**2\n",
    "    \n",
    "    return sqrt(distance)\n",
    "\n",
    "\n",
    "def get_neighbors(train, test_row, num_neighbors):\n",
    "    \"\"\"\n",
    "    Identifie les 'k' voisins les plus proches d'une ligne donnée dans l'ensemble d'entraînement.\n",
    "\n",
    "    Args:\n",
    "        train (list): L'ensemble d'entraînement sous forme de liste.\n",
    "        test_row (list): Une ligne de l'ensemble de test pour laquelle on cherche les voisins.\n",
    "        num_neighbors (int): Le nombre de voisins à considérer.\n",
    "\n",
    "    Returns:\n",
    "        list: Les 'k' voisins les plus proches sous forme de liste.\n",
    "    \"\"\"\n",
    "    distances = list()\n",
    "    for train_row in train:\n",
    "        dist = euclidean_distance(test_row, train_row)\n",
    "        distances.append((train_row, dist))\n",
    "    distances.sort(key=lambda tup: tup[1])\n",
    "    neighbors = list()\n",
    "    for i in range(num_neighbors):\n",
    "        neighbors.append(distances[i][0])\n",
    "    return neighbors\n",
    "\n",
    "\n",
    "def predict_classification(train: pd.DataFrame, test_row, num_neighbors):\n",
    "    \"\"\"\n",
    "    Prédit la classe d'une ligne de test basée sur les classes des 'k' voisins les plus proches.\n",
    "\n",
    "    Args:\n",
    "        train (list): L'ensemble d'entraînement sous forme de liste.\n",
    "        test_row (list): Une ligne de test pour laquelle on veut prédire la classe.\n",
    "        num_neighbors (int): Le nombre de voisins à considérer.\n",
    "\n",
    "    Returns:\n",
    "        int/str: La classe prédite (dépend des données).\n",
    "    \"\"\"\n",
    "    neighbors = get_neighbors(train, test_row, num_neighbors)\n",
    "    output_values = [row[0] for row in neighbors]\n",
    "    #print(f\"Output values classification: {output_values}\")\n",
    "    prediction = max(set(output_values), key=output_values.count)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def accuracy_metric(actual: list[float], predicted: list[float]):\n",
    "    \"\"\"\n",
    "    Calcule le pourcentage de précision des prédictions.\n",
    "\n",
    "    Args:\n",
    "        actual (list): Liste des classes réelles.\n",
    "        predicted (list): Liste des classes prédites.\n",
    "\n",
    "    Returns:\n",
    "        float: Pourcentage de précision (valeur entre 0 et 100).\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0\n",
    "\n",
    "\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    \"\"\"\n",
    "     Divise le dataset en 'n_folds' sous-ensembles pour effectuer une validation croisée.\n",
    "\n",
    "    Args:\n",
    "        dataset (list): Le dataset initial sous forme de liste.\n",
    "        n_folds (int): Le nombre de sous-ensembles (folds) à créer.\n",
    "\n",
    "    Returns:\n",
    "        list: Une liste contenant 'n_folds' sous-ensembles, chacun étant une partie du dataset.\n",
    "\n",
    "    \"\"\"\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for _ in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97128914",
   "metadata": {},
   "source": [
    "Création de deux datasets: \n",
    "- un avec les données brutes\n",
    "- un avec les données normalisées\n",
    "\n",
    "**Lisez sans modifier le code ci-dessous pour en comprendre le sens et répondez aux questions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f0ca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des datasets - rien à modifier\n",
    "\n",
    "#=====================================================================\n",
    "# Préparation des données brutes \n",
    "#=====================================================================\n",
    "\n",
    "# Conversion en liste de listes au lieu de DataFrame\n",
    "data = wines.values.tolist()\n",
    "\n",
    "#=====================================================================\n",
    "# Préparation des données normalisées\n",
    "#=====================================================================\n",
    "\n",
    "\n",
    "# Différents moyens de standardiser les données mise à disposition par Scikit-learn\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "\n",
    "# Nous allons utiliser le StandardScaler, qui va normaliser les données avec une moyenne de 0 et un écart-type de 1\n",
    "scaler = StandardScaler()\n",
    "scaler_string = \"StandardScaler\" # pour l'affichage dans le titre des plots si nécessaire\n",
    "\n",
    "\n",
    "# Créer une copie et prendre une liste des colonnes des données indépendantes (entrées)\n",
    "df_normalized = wines.copy()\n",
    "cols = wines.columns[wines.columns != 'Note']\n",
    "\n",
    "# Remplacer les colonnes des données par les données transformées\n",
    "df_normalized[cols] = scaler.fit_transform(df_normalized[cols])\n",
    "\n",
    "# conversion en liste de listes pour k-NN\n",
    "data_normalized = df_normalized.values.tolist()\n",
    "\n",
    "# K's à tester\n",
    "Ks = [1, 2, 3, 5, 7, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90187871",
   "metadata": {},
   "source": [
    "**Ci-dessous, affichez les boxplots des données normalisées, comme pour les données du [point 1.2](#Part12).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e2c161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliser les données (exclure 'Class')\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "data_normalized = scaler.fit_transform(df_normalized.drop(columns=['Class']))\n",
    "\n",
    "# Créer un DataFrame normalisé en ajoutant les noms de colonnes\n",
    "\n",
    "df_normalized_boxplot = pd.DataFrame(data_normalized, columns=df_normalized.columns[:-1])\n",
    "\n",
    "# Créer les boxplots\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "sns.boxplot(data=df_normalized_boxplot, palette=\"Set2\")\n",
    "\n",
    "plt.title(\"Boxplots des données normalisées (MinMaxScaler)\", fontsize=16)\n",
    "\n",
    "plt.xlabel(\"Variables\", fontsize=12)\n",
    "\n",
    "plt.ylabel(\"Valeurs normalisées\", fontsize=12)\n",
    "\n",
    "plt.xticks(rotation=45)  # Rotation des étiquettes pour une meilleure lisibilité\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Affichage\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef1af41",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font>Quelle est la différence entre un commentaire et une docstring ? </p> (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5379e048",
   "metadata": {},
   "source": [
    "*Réponse:* Un commentaire est une note incluse dans le code pour expliquer son fonctionnement et une docstring est une chaîne de caractères qui documente un module, une classe, une méthode ou une fonction. Contrairement aux commentaires, les docstrings sont conçues pour être accessibles dynamiquement via des outils comme __doc__\n",
    "\n",
    "Source : https://www.docstring.fr/glossaire/docstring/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27f2785",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font> Qu'est-ce que la normalisation des données ? </p> (1 point)\n",
    "\n",
    "Décrivez le concept en quelques mots. Attention, les termes \"Normalisation\" et \"Standardisation\" sout souvents mélangés mais le concept général reste le même !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32100608",
   "metadata": {},
   "source": [
    "*Réponse:* La normalisation des données est une technique utilisée en prétraitement des données pour transformer les valeurs des variables dans une plage commune ou comparable, afin de faciliter l'analyse et d'améliorer les performances des algorithmes d'apprentissage automatique.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860a9e22",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font> Quelles sont les différences entre les StandardScaler, MinMaxScaler et RobustScaler ?</p> (3 points)\n",
    "\n",
    "Note: Aidez-vous de [la doc](https://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling) ou d'autres ressources pour répondre. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417fe016",
   "metadata": {},
   "source": [
    "*Réponse:* \n",
    "\n",
    "StandardScaler :\n",
    "\n",
    "- Centrage sur une moyenne de 0 et écart-type de 1.\n",
    "- Sensible aux outliers (valeurs extrêmes).\n",
    "\n",
    "MinMaxScaler :\n",
    "\n",
    "- Mise à l'échelle entre 0 et 1 (ou autre intervalle choisi).\n",
    "- Sensible aux outliers car basé sur les minimum et maximum.\n",
    "\n",
    "RobustScaler :\n",
    "\n",
    "- Utilise la médiane et l'IQR (Intervalle Interquartile).\n",
    "- Résistant aux outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0656ae66",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font> Quelles différences observez-vous entre les boxplots des données originales du point 1.2 par rapport aux boxplots avec les données normalisées ?</p>(1 points)\n",
    "\n",
    "Voir [point 1.2](#Part12)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a5cc82",
   "metadata": {},
   "source": [
    "*Réponse:* \n",
    "\n",
    "- Échelle uniforme : Les données normalisées ont toutes leurs valeurs entre 0 et 1, rendant les comparaisons entre variables plus claires. Dans les données originales, les échelles varient fortement (par ex. proline vs hue).\n",
    "\n",
    "- Visibilité des variables : Dans les données normalisées, les variables moins dominantes (comme hue) deviennent aussi visibles que les autres.\n",
    "\n",
    "- Analyse simplifiée : La normalisation met en évidence les différences entre classes pour toutes les variables, facilitant l'identification des caractéristiques discriminantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f4c455",
   "metadata": {},
   "source": [
    "<a name=\"Part21pts\"></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Corrections Partie 2.1: </b> Points obtenus: /12\n",
    "</div>\n",
    "\n",
    "Remarques de l'assistant: \n",
    "\n",
    "- docstrings: /6\n",
    "- Questions: /6\n",
    "\n",
    "\n",
    "[Début partie 2](#Part2) --- [Table des matières](#toc)\n",
    "\n",
    "<p style=\"background-color:#003c9c;padding:3px\"><font size=\"4\"><b></b></font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550f0af3",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<a name=\"Part22\"></a>\n",
    "### 2.2 Validation hold-out\n",
    "[Table des matières](#toc)\n",
    "\n",
    "Nous allons ici utiliser la méthode \"Validation Hold-Out\" avec k-NN sur nos données. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16bf8f4",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Exercice </b></font> Complétez le code ci-dessous en suivant les indications en commentaire. Respectez le nombre de lignes indiqué.</p> (6 points)\n",
    "\n",
    "\n",
    "\n",
    "Utilisez en premier le dataset \"***data***\" puis une fois votre code fonctionnel, ajoutez un niveau de boucle et effectuez la même opération en plus pour le dataset avec les données normalisées: \"***data_normalized***\". \n",
    "\n",
    "\n",
    "\n",
    "*Supprimez aussi le print() dans la boucle qui est là pour que le code fonctionne avant que vous l'ayez complété.* \n",
    "\n",
    "Aide: \n",
    "- Vous devez modifier différentes variables, comme par exemple ajouter une dimention à la variable qui contient les résultats. Pour cela on vous conseille de créer deux dictionnaires (comme c'est déjà fait), un pour les données originales et un pour les données normalisées puis de créer une liste \"results\" contenant vos deux dictionnaires de résultats. N'oubliez pas de modifier le titre des graphiques pour plus de clareté (indiquez quel données sont utilisées). \n",
    "- Si vous voulez boucler sur les éléments d'une liste (contenant par exemple deux datasets) vous pouvez utiliser la fonction *enumerate()* qui retourne chaque élément en plus d'un indice (qu'on appelera j ou l par exemple)\n",
    "- Pour adapter le titre de vos graphiques, vous pouvez simplement créer une liste avec deux titres et utiliser votre variable de boucle pour choisir le bon titre\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc68bd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complétez le code ci-dessous. Attention, les données sont dans \"data\"/\"data_normalized\" et non dans \"wines\":\n",
    "\n",
    "\n",
    "# Nous voulons 10 répétitions avec la méthode validation hold-out\n",
    "N_REPETITIONS = 10\n",
    "\n",
    "# Nous allons stocker les résultats dans un dictionnaire, avec pour chaque k une liste d'accuracy. \n",
    "results = defaultdict(list)\n",
    "\n",
    "# Liste des datasets et des titres associés\n",
    "datasets = [data, data_normalized]\n",
    "titles = ['Données Originales', 'Données Normalisées']\n",
    "\n",
    "# Boucle principale pour chaque dataset\n",
    "for j, dataset in enumerate(datasets):\n",
    "    # Pour chaque validation hold-out (test et train set différents) on test chaque k\n",
    "    for i in range(N_REPETITIONS):\n",
    "        for k in Ks:\n",
    "            # Vous pouvez supprimer cette ligne une fois votre code fonctionnel\n",
    "            # Pour que le code tourne, la boucle ne doit pas être vide ;-)  \n",
    "            \n",
    "            # Faire le train-test split avec split = 0.8. \n",
    "            # La fonction retourne deux éléments, utilisez le unpacking pour les extraire (train, test = fct())\n",
    "            # - complétez - 1 ligne\n",
    "            train, test = train_test_split(dataset,split=0.8)\n",
    "    \n",
    "            # Aide: utilisez la compréhension de liste:  prédictions = [prediction(...) for ... in ...] \n",
    "            #                                                                           pour chaque observation de test\n",
    "            #       Vous devez générer une liste de prédictions (1, 2 ou 3), que vous comparerez en dessous avec \n",
    "            #         les valeurs justes pour obtenir l'accuracy.\n",
    "            \n",
    "            # - complétez - 1 ligne\n",
    "            predictions = [predict_classification(train, row, k) for row in test]\n",
    "    \n",
    "            # Joindre à results[k] la liste des accuracies (obtenu avec la fonction accuracy_metric() ci dessus)\n",
    "            # Aide: utilisez la méthode append() pour joindre l'accuracy aux résultats\n",
    "            # Aide: utilisez la méthode accuracy_metric() pour obtenir l'accuracy\n",
    "            # Aide: Vous avez une liste de prédictions et un dataframe original (test)\n",
    "            #       utilisez la compréhension de liste pour créer la liste des données originales:\n",
    "            #         [colone \"note\" pour chaque ligne des tests]\n",
    "            \n",
    "            # - complétez - 1 ligne (si vous y arrivez, sinon plus)\n",
    "            \n",
    "            results[k].append(accuracy_metric([row[0] for row in test], predictions))\n",
    "    \n",
    "    \n",
    "    # Une fois le code fonctionnel, vous devrez bouger le graphique à l'intérieur de la boucle \n",
    "    # N'oubliez pas de changer le titre selon les données utilisées !\n",
    "    \n",
    "    _, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "    \n",
    "    means = [np.mean(v) for v in results.values()]\n",
    "    stds = [np.std(v) for v in results.values()]\n",
    "    \n",
    "    ax.errorbar(results.keys(), means, stds, linestyle='None', marker='D', color='darkgreen')\n",
    "    ax.set_ylabel('Accuracy', fontsize=12)\n",
    "    ax.set_xlabel('K', fontsize=12)\n",
    "    ax.set_title(f'Performance of classification with various K using K-NN ({titles[j]})', fontsize=14)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.4, lw=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d9023e",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font> Pour quelle valeur(s) de k le modèle est-il le plus efficace sans et avec les données normalisées ? Une fois les données normalisées, quelle différence observe-t-on ? Justifiez.</p>\n",
    "(2 points)\n",
    "\n",
    "Note: Les résultats peuvent varier d'une exécution à l'autre. Indiquez la tendance générale que vous observez.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996dc483",
   "metadata": {},
   "source": [
    "*Réponse:*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9eef03",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font> Pourquoi les résultats varient d'une exécution à une autre ? Décrivez le fonctionnement de ce que vous venez de faire (point 2.1) en quelques phrases.</p> (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2a336d",
   "metadata": {},
   "source": [
    "*Réponse:*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d31d39",
   "metadata": {},
   "source": [
    "<a name=\"Part22pts\"></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Corrections Partie 2.2: </b> Points obtenus: /10\n",
    "</div>\n",
    "\n",
    "Remarques de l'assistant: \n",
    "\n",
    "- Exercice code: /6\n",
    "- Q /4\n",
    "\n",
    "\n",
    "[Début partie 2](#Part2) --- [Table des matières](#toc)\n",
    "\n",
    "<p style=\"background-color:#003c9c;padding:3px\"><font size=\"4\"><b></b></font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4f16db",
   "metadata": {},
   "source": [
    "\n",
    "<a name=\"Part23\"></a>\n",
    "### 2.3 N-Folds cross validation\n",
    "[Table des matières](#toc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5838b7bc",
   "metadata": {},
   "source": [
    "Si vous voulez vous raffraichir sur ce qu'est la N-Fold Cross Validation, voici [une courte vidéo de StatQuest](https://www.youtube.com/watch?v=fSytzGwwBVw) (ou [une autre en français](https://www.youtube.com/watch?v=xWgGOHiROmc)).\n",
    "\n",
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Exercice </b></font> Complétez le code ci-dessous en suivant les indications en commentaire, cette fois en utilisant la N-fold cross validation.</p>(6 points)\n",
    "\n",
    "Note: \n",
    "- Aussi appelée k-fold cross validation dans la litérature, mais là on veut pas confondre avec notre k de k-NN. \n",
    "\n",
    "Utilisez en premier le dataset \"***data***\" puis une fois votre code fonctionnel, ajoutez un niveau de boucle et ajoutez le dataset avec les données normalisées: \"***data_normalized***\" comme au [point 2.2](#Part22). N'oubliez pas de modifier les parties nécessaires ainsi que le titre des graphiques pour que le résultat soit lisible. \n",
    "\n",
    "*Supprimez aussi le print() dans la boucle qui est là pour que le code fonctionne avant que vous l'ayez complété.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d673a987",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_nfold = defaultdict(list)\n",
    "\n",
    "# Les données sont divisées en plusieurs folds \n",
    "folds = cross_validation_split(data, n_folds=5)\n",
    "\n",
    "\n",
    "# Boucle sur les datasets\n",
    "for j, dataset in enumerate(datasets):  \n",
    "    for k in Ks:\n",
    "        \n",
    "        # Listes qui vont contenir les valeurs prédites et les vraies valeurs\n",
    "        predictions = []\n",
    "        actuals = []\n",
    "    \n",
    "        for test_i in range(len(folds)):\n",
    "            # print(f\"----- Fold = {test_i } - k = {k} -----\") \n",
    "            \n",
    "            # train = tout sauf le fold i, qui est utilisé pour tester.\n",
    "            # Permet de créer une liste à partir des éléments de folds, y compris si c'est vide. \n",
    "            train = list(itertools.chain.from_iterable(folds[:test_i] + folds[test_i+1:]))\n",
    "                \n",
    "            # test = Fold courrant, utilisé pour tester\n",
    "            # - complétez - 1 ligne\n",
    "            test = folds[test_i]\n",
    "            \n",
    "            \n",
    "            # Effectue la prédiction et l'ajoute au tableau prédictions[] pour chaque element dans test\n",
    "            # predictions += [...fonction pour faire la classification définie en début de point 2.... for....in ....]\n",
    "            # - complétez - 1 ligne\n",
    "            predictions += [predict_classification(train, row, k) for row in test]\n",
    "                    \n",
    "            \n",
    "            # Remplit la liste \"actual\" avec les valeurs réelles (actuals += ... )\n",
    "            # - complétez - 1 ligne\n",
    "            actuals += [row[0] for row in test] \n",
    "        \n",
    "        # Mettez le résultat de \"accuracy_metric(...,...)\" dans results_nfold[k]\n",
    "        # - complétez - 1 ligne\n",
    "        accuracy = accuracy_metric(actuals, predictions)\n",
    "        results_nfold[k].append(accuracy) \n",
    "        \n",
    "        print(f'Performance with k={k}: {results_nfold[k]}')\n",
    "        \n",
    "    _, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "    \n",
    "    \n",
    "    # Une fois le code fonctionnel pour un dataset, vous devrez bouger les graphiques à l'intérieur de la boucle \n",
    "    # comme au point 2.2. \n",
    "    \n",
    "    ax.plot(results_nfold.keys(), results_nfold.values(), linestyle='None', marker='D')\n",
    "    ax.set_ylabel('Accuracy', fontsize=12)\n",
    "    ax.set_xlabel('K', fontsize=12)\n",
    "    ax.set_title(f'Performance of classification with various K using K-NN (K-fold cross-validation)({titles[j]})', fontsize=14)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.4, lw=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d450a1",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font> Quelle différence dans les code des points 2.2 (validation hold-out et 2.3 (N-Fold cross validation) fait que nous n'avons qu'un seul point par k et non une moyenne et écart-type ? </p>(2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bb98cc",
   "metadata": {},
   "source": [
    "*Réponse:*\n",
    "La différence réside dans le fait que pour la validation hold-out, on obtient un seul score d'accuracy par valeur de k. Alors que pour la validation croisée (N folds), on obtient une moyenne et un écart-type des résultats de précision pour chaque valeur de k, en utilisant les résultats de tous les folds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3d227c",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font>Les résultats varient-ils d'une exécution à l'autre ? Décrivez le fonctionnement de ce que vous venez de faire (point 2.2) en quelques phrases. </p>(2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dbc9a6",
   "metadata": {},
   "source": [
    "*Réponse:*\n",
    "Dans le point 2.2 (validation hold-out), les données sont divisées en deux ensembles : un pour l'entraînement et un autre pour le test. Le modèle k-NN est ensuite entraîné sur l'ensemble d'entraînement et testé sur l'ensemble de test pour chaque valeur de k. L'accuracy, c'est-à-dire le taux de bonnes prédictions, est calculée et enregistrée pour chaque valeur de k. Cette procédure est répétée pour plusieurs valeurs de k afin d'identifier la meilleure configuration. Comme l'échantillonnage est aléatoire, les résultats peuvent varier légèrement d'une exécution à l'autre.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb465bb9",
   "metadata": {},
   "source": [
    "<a name=\"Part23pts\"></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Corrections Partie 2.3: </b> Points obtenus: /10\n",
    "</div>\n",
    "\n",
    "Remarques de l'assistant: \n",
    "- code /6\n",
    "- Q /4\n",
    "\n",
    "\n",
    "[Début partie 2](#Part2) --- [Table des matières](#toc)\n",
    "\n",
    "<p style=\"background-color:#003c9c;padding:3px\"><font size=\"4\"><b></b></font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbe439f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<a name=\"Part24\"></a>\n",
    "### 2.4 Conclusion\n",
    "[Début partie 2](#Part2) --- [Table des matières](#toc)\n",
    "\n",
    "\n",
    "\n",
    "Répondez aux questions suivantes **en faisant des phrases**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4481d44c",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font> Quels sont les principaux avantages de l'utilisation des modèles basés sur des règles par rapport à d'autres algorithmes d'apprentissage automatique comme le KNN ? </p>(2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bc4a4f",
   "metadata": {},
   "source": [
    "*Réponse:*\n",
    "Les modèles basés sur des règles, comme les arbres de décision, sont plus interprétables, rapides en prédiction, et moins sensibles au bruit que le KNN. Ils gèrent mieux les variables catégorielles et modélisent facilement les relations non linéaires, contrairement au KNN qui est plus lent et dépend des distances, rendant l'interprétation plus complexe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dffa84",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font>Comparez et contrastez les techniques de validation hold-out et de N-Fold Cross Validation dans le contexte de l'évaluation des performances d'un classifieur KNN. </p>(4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325fc5ff",
   "metadata": {},
   "source": [
    "*Réponse:*\n",
    "La validation hold-out divise les données en un ensemble d'entraînement et un ensemble de test, mais les résultats peuvent varier selon la partition. La N-Fold Cross Validation utilise plusieurs sous-ensembles pour tester chaque donnée, offrant une évaluation plus robuste et moins biaisée, mais au coût de temps de calcul plus élevé."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9ec16c",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#AFEEEE;padding:3px\"><font size=\"4\"><b>Q </b></font>Comment la nature \"lazy learning\" du KNN impacte-t-elle ses performances et son efficacité computationnelle par rapport à d'autres algorithmes ? </p>(2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f24a342",
   "metadata": {},
   "source": [
    "*Réponse:*\n",
    "La nature \"lazy learning\" du KNN signifie qu'il n'apprend pas pendant l'entraînement, mais compare chaque nouvelle instance avec toutes les données d'entraînement lors de la prédiction, ce qui le rend précis mais computationalement coûteux. Contrairement à d'autres algorithmes comme les arbres de décision, qui apprennent un modèle et prédisent plus rapidement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90625bf3",
   "metadata": {},
   "source": [
    "<a name=\"Part24pts\"></a>\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Corrections Partie 2.4: </b> Points obtenus: /8\n",
    "</div>\n",
    "\n",
    "Remarques de l'assistant: \n",
    "\n",
    "\n",
    "[Début partie 2](#Part2) --- [Table des matières](#toc)\n",
    "\n",
    "<p style=\"background-color:#003c9c;padding:3px\"><font size=\"4\"><b></b></font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28f3f95",
   "metadata": {},
   "source": [
    "Fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
